{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import related libraries. For this task I am using scikit-learn package for building models and pandas module to read input data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Read and prepare data from 'spambase.data' file. We sprate column 57 out to as the target (spam vs non-spam). Leave out 30% of the data as testing set. Perform a sanity check on the shape of training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3220, 57), (3220,))"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_data = pd.read_csv('spambase.data', header=None)\n",
    "spam_target = spam_data.pop(57)\n",
    "X_train, X_test, y_train, y_test = train_test_split(spam_data, spam_target, test_size=0.3, random_state=0)\n",
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use a random forest classifer with 100 decision trees for this task, given its resistence to overfitting, and high accuracy in overall classification performance. We'll build each decision tree based on information gain (decrease in entropy)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(criterion='entropy', n_estimators = 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Prepare custom score functions for cross_validation. We'll utilize scikit-learn's confusion_matrix function to obtain false positive and false negative value, and since the error rate $(FP+FN)/(P+N)$ = 1.0 - $(TP+TN)/(P+N)$ = 1.0 - accuracy, we obtain it through scikit-learn's accuracy_score function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def fp(y_true, y_pred): return confusion_matrix(y_true, y_pred)[0, 1]\n",
    "def fn(y_true, y_pred): return confusion_matrix(y_true, y_pred)[1, 0]\n",
    "def err(y_true, y_pred): return 1.0 - accuracy_score(y_true, y_pred)\n",
    "scoring = {'fp': make_scorer(fp), 'fn': make_scorer(fn), 'err': make_scorer(err)}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perform corss validation with 10 folds. Get the false positive, false negative, and error rate for each fold to store in scores dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = cross_validate(rf, X_train, y_train, cv=10, scoring = scoring,\n",
    "                        return_train_score = False, return_estimator = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Output the table for the above scores, compute the average across all 10 folds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold     False Positive  False Negative  Error Rate     \n",
      "1        6               2               0.024767801857585092\n",
      "2        6               10              0.049535603715170295\n",
      "3        9               11              0.0619195046439629\n",
      "4        5               14              0.05882352941176472\n",
      "5        3               12              0.04658385093167705\n",
      "6        9               10              0.05900621118012417\n",
      "7        8               7               0.04672897196261683\n",
      "8        4               12              0.049844236760124616\n",
      "9        6               6               0.03738317757009346\n",
      "10       3               8               0.034267912772585674\n",
      "avg.     5.9             9.2             0.04688608008057048\n"
     ]
    }
   ],
   "source": [
    "print(\"{:<8} {:<15} {:<15} {:<15}\".format('Fold','False Positive','False Negative','Error Rate'))\n",
    "fp_array, fn_array, err_array = scores['test_fp'], scores['test_fn'], scores['test_err']\n",
    "for i in range(10):\n",
    "    print(\"{:<8} {:<15} {:<15} {:<15}\".format(i+1,fp_array[i],fn_array[i],err_array[i]))\n",
    "print(\"{:<8} {:<15} {:<15} {:<15}\".format('avg.',sum(fp_array)/10,sum(fn_array)/10,sum(err_array)/10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also fit on the entire training data and then perform accuracy test on test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9500362056480811"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf.fit(X_train, y_train)\n",
    "rf.score(X_test, y_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
